{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "capital-middle",
   "metadata": {
    "tags": []
   },
   "source": [
    "### About the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-hollow",
   "metadata": {},
   "source": [
    "In this is notebook to test out ONNX based inference. Load saved model and predict succesfully. Do not worry about slow prediction. It seems first prediction is always slow, while all of the following ones are fast. Perhaps first one includes setup of objects or similar slow operations. To solve this we can just run a single empty prediction in the server right on server start.\n",
    "- ```size``` - set this to your last export size matching the to_onnx export in the GoBig notebook. This will have to match with ```MODEL_SIZE``` constant in the model_server.py too. We always use square sizes, because it's easier for NNs to learn these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "primary-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liquid-hammer",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ONNX inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "korean-commodity",
   "metadata": {},
   "outputs": [],
   "source": [
    "#even if we don't use the function anywhere, we need to define it, otherwise it will error out when unpickling.\n",
    "def label_func(fn): return os.path.join(path,\"labels\",f\"{fn.stem}{fn.suffix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "european-treat",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import PILImage, get_image_files\n",
    "from fastinference.onnx import *\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import pathlib\n",
    "from notebook_libs.helper_funcs import onnx_model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "phantom-vegetable",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = pathlib.Path().absolute()\n",
    "path = os.path.join(path, \"Assets\", \"Data~\")\n",
    "save_name = \"unity_resnet34\"+\"_\"+str(size)+\"x\"\n",
    "fnames = get_image_files(os.path.join(path,\"screenshots\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-change",
   "metadata": {},
   "source": [
    "Next we load the model. We can change the appended name \"64x\" to something else, if we saved the model via to_onnx in the GoBig notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-expert",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this should show pairs of .pkl and .onnx for each properly saved model via to_onnx\n",
    "onnx_model_names(os.path.join(path, \"models/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "threaded-ribbon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu: False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "onnx_path = os.path.join(path, \"models/\", save_name+\"_onnx\")\n",
    "onnx_learn = fastONNX(onnx_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "selective-understanding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256)\n",
      "torch.Size([3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "pil_img = PILImage.create(fnames[0])\n",
    "resize = transforms.Resize([size, size])\n",
    "pil_img = resize(pil_img)\n",
    "print(pil_img.shape)\n",
    "to_tensor = transforms.ToTensor()\n",
    "ten_image = to_tensor(pil_img)\n",
    "print(ten_image.shape)\n",
    "ten_image = ten_image.unsqueeze_(0)\n",
    "print(ten_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-bidder",
   "metadata": {},
   "source": [
    "Then we run .predict and time it. Important! This is not same predict as imported form fastinference! That one did not work for our purposes in image segmentation, so I modified it a bit to fit. You can check source with \"??onnx_learn.predict\" cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "finnish-orange",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>  predict shape:  torch.Size([1, 3, 256, 256])\n",
      "CPU times: user 331 ms, sys: 125 ms, total: 456 ms\n",
      "Wall time: 955 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_output = onnx_learn.predict(ten_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "listed-information",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 256, 256)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-belize",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
